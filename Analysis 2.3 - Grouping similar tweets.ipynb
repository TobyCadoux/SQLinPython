{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-definitions\" data-toc-modified-id=\"Imports-and-definitions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and definitions</a></span></li><li><span><a href=\"#Load-tables\" data-toc-modified-id=\"Load-tables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load tables</a></span></li><li><span><a href=\"#Text-association\" data-toc-modified-id=\"Text-association-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Text association</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2 - Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime as dt\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "plt.style.use('fivethirtyeight') #Generally nice\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from pandasql import sqldf\n",
    "sql = lambda x: sqldf(x, globals())\n",
    "from textblob import TextBlob\n",
    "path = 'output_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = pd.read_parquet(path+'cleantweets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv(path+'user.csv')\n",
    "topwords = pd.read_csv(path+'topwords.csv')\n",
    "#hashtag = pd.read_csv(path+'hashtag.csv')\n",
    "#mention = pd.read_csv(path+'mention.csv')\n",
    "#tweet_hashtag = pd.read_csv(path+'tweet_hashtag.csv')\n",
    "#tweet_mention = pd.read_csv(path+'tweet_mention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topwords = topwords.iloc[0:5000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.34 s, sys: 46.6 ms, total: 7.39 s\n",
      "Wall time: 7.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Set up the incidence matrix\n",
    "inc_mat=CountVectorizer(vocabulary=topwords.word)\n",
    "X = inc_mat.fit_transform(tweet.wordtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 23.7 s, total: 1min 7s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Feature extraction\n",
    "n_components=8\n",
    "nmf = NMF(n_components=n_components, solver='mu')\n",
    "W = nmf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 top 12 words: proud, time, join, ago, meeting, years, us, pm, honor, office, thanks, today\n",
      "Cluster 2 top 12 words: proud, people, act, need, congress, must, thanks, support, time, help, work, us\n",
      "Cluster 3 top 12 words: yesterday, school, discussion, visit, meet, news, students, morning, see, meeting, thanks, great\n",
      "Cluster 4 top 12 words: pass, committee, white, gop, bipartisan, act, vote, floor, senate, passed, bill, house\n",
      "Cluster 5 top 12 words: law, plan, mental, coverage, women, insurance, affordable, access, act, americans, care, health\n",
      "Cluster 6 top 12 words: news, check, center, create, happy, report, congrats, york, state, year, jobs, new\n",
      "Cluster 7 top 12 words: first, veterans, women, honor, national, service, every, birthday, th, happy, thank, day\n",
      "Cluster 8 top 12 words: et, join, listen, tonight, floor, morning, discuss, tune, pm, hearing, live, watch\n"
     ]
    }
   ],
   "source": [
    "nwords = 12\n",
    "tw = np.array(inc_mat.get_feature_names())\n",
    "for i, topic in enumerate(nmf.components_):\n",
    "    terms = [str(term) for term in tw[topic.argsort()[-nwords:]]]\n",
    "    terms = ', '.join(terms)\n",
    "    print(f'Cluster {i+1} top {nwords} words: {terms}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cluster 1: general thanks for political support over time\n",
    "* Cluster 2: support for American jobs\n",
    "* Cluster 3: schools and education discussions\n",
    "* Cluster 4: reporting on legislation and congress debates\n",
    "* Cluster 5: access to healthcare and mental health\n",
    "* Cluster 6: New York jobs and services\n",
    "* Cluster 7: support for military veterans\n",
    "* Cluster 8: drumming up audiences for political shows"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
