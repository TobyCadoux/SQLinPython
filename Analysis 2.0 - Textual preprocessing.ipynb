{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-definitions\" data-toc-modified-id=\"Imports-and-definitions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and definitions</a></span></li><li><span><a href=\"#Load-tables\" data-toc-modified-id=\"Load-tables-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load tables</a></span></li><li><span><a href=\"#Text-preprocessing\" data-toc-modified-id=\"Text-preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Text preprocessing</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "from nlppreprocess import NLP\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "processor = NLP()\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output_data/'\n",
    "tweet = pd.read_csv(path+'tweet.csv', lineterminator='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spent *hours* on this and then I found tweet-preprocessor which I added to the\n",
    "tweet import notebook.\n",
    "\n",
    "Here I'll only be preprocessing the *text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.09 s, sys: 64.6 ms, total: 9.15 s\n",
      "Wall time: 9.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweet.set_index('id', inplace=True)\n",
    "# Lower the text\n",
    "tweet['text']=tweet['text'].str.lower()\n",
    "# Expand some negative sentiments and common suffixes\n",
    "tweet['text']=tweet['text'].str.replace(\"can\\'t\",\"cannot\")\n",
    "tweet['text']=tweet['text'].str.replace(\"n\\'t\",\"\\ not\")\n",
    "tweet['text']=tweet['text'].str.replace(\"\\'d\",\"\\ had\")\n",
    "tweet['text']=tweet['text'].str.replace(\"\\'ve\",\"\\ have\")\n",
    "tweet['text']=tweet['text'].str.replace(\"\\'ll\",\"\\ will\")\n",
    "tweet['text']=tweet['text'].str.replace(\"\\'re\",\"\\ are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 87.9 ms, total: 17.5 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the preprocessor\n",
    "tweet['text']=tweet['text'].apply(processor.process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 19.8 ms, total: 1.35 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# There's still noise!\n",
    "tweet['text']=tweet['text'].str.replace('\\ [^ia]\\ ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 1.55 s, total: 54.9 s\n",
      "Wall time: 54.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tokenize to obtain a list\n",
    "tweet['words'] = tweet['text'].astype(str).apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 44 ms, total: 4.65 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Eliminate stop words\n",
    "sw.add('amp')\n",
    "def remove_stopwords(wordlist, stopwords=sw):\n",
    "    return [word for word in wordlist if word not in stopwords and len(word)>1]\n",
    "tweet['words']=tweet['words'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine words into sentences again - but now without the junk!\n",
    "tweet['wordtext'] = tweet['words'].apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>wordtext</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>877418565</th>\n",
       "      <td>2008-08-04 17:28:51</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>conference call about weekend trip iraq visit arkansas troops</td>\n",
       "      <td>[conference, call, weekend, trip, iraq, visit, arkansas, troops]</td>\n",
       "      <td>conference call weekend trip iraq visit arkansas troops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879695803</th>\n",
       "      <td>2008-08-06 20:35:36</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>being interviewed by karn his arkansas world trade center trip</td>\n",
       "      <td>[interviewed, karn, arkansas, world, trade, center, trip]</td>\n",
       "      <td>interviewed karn arkansas world trade center trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880393665</th>\n",
       "      <td>2008-08-07 13:52:52</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>kwhn in fort smith  that am</td>\n",
       "      <td>[kwhn, fort, smith]</td>\n",
       "      <td>kwhn fort smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880474266</th>\n",
       "      <td>2008-08-07 15:12:05</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>attending military purple heart ceremony va medical center in fayetteville</td>\n",
       "      <td>[attending, military, purple, heart, ceremony, va, medical, center, fayetteville]</td>\n",
       "      <td>attending military purple heart ceremony va medical center fayetteville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880676101</th>\n",
       "      <td>2008-08-07 18:35:25</td>\n",
       "      <td>0</td>\n",
       "      <td>JohnBoozman</td>\n",
       "      <td>touring helath south hospital in fayetteville</td>\n",
       "      <td>[touring, helath, south, hospital, fayetteville]</td>\n",
       "      <td>touring helath south hospital fayetteville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at  retweet_count  screen_name  \\\n",
       "id                                                           \n",
       "877418565  2008-08-04 17:28:51              0  JohnBoozman   \n",
       "879695803  2008-08-06 20:35:36              0  JohnBoozman   \n",
       "880393665  2008-08-07 13:52:52              0  JohnBoozman   \n",
       "880474266  2008-08-07 15:12:05              0  JohnBoozman   \n",
       "880676101  2008-08-07 18:35:25              0  JohnBoozman   \n",
       "\n",
       "                                                                                 text  \\\n",
       "id                                                                                      \n",
       "877418565               conference call about weekend trip iraq visit arkansas troops   \n",
       "879695803              being interviewed by karn his arkansas world trade center trip   \n",
       "880393665                                                 kwhn in fort smith  that am   \n",
       "880474266  attending military purple heart ceremony va medical center in fayetteville   \n",
       "880676101                               touring helath south hospital in fayetteville   \n",
       "\n",
       "                                                                                       words  \\\n",
       "id                                                                                             \n",
       "877418565                   [conference, call, weekend, trip, iraq, visit, arkansas, troops]   \n",
       "879695803                          [interviewed, karn, arkansas, world, trade, center, trip]   \n",
       "880393665                                                                [kwhn, fort, smith]   \n",
       "880474266  [attending, military, purple, heart, ceremony, va, medical, center, fayetteville]   \n",
       "880676101                                   [touring, helath, south, hospital, fayetteville]   \n",
       "\n",
       "                                                                          wordtext  \n",
       "id                                                                                  \n",
       "877418565                  conference call weekend trip iraq visit arkansas troops  \n",
       "879695803                        interviewed karn arkansas world trade center trip  \n",
       "880393665                                                          kwhn fort smith  \n",
       "880474266  attending military purple heart ceremony va medical center fayetteville  \n",
       "880676101                               touring helath south hospital fayetteville  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2419.27 MiB, increment: 596.22 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "tweet.to_parquet(path+'cleantweets.parquet')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
