{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Tweet-data-import\" data-toc-modified-id=\"Tweet-data-import-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tweet data import</a></span><ul class=\"toc-item\"><li><span><a href=\"#Small-subset-initial-import\" data-toc-modified-id=\"Small-subset-initial-import-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Small subset initial import</a></span></li><li><span><a href=\"#Feature-selection\" data-toc-modified-id=\"Feature-selection-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Feature selection</a></span></li><li><span><a href=\"#Full-datset-languages-check\" data-toc-modified-id=\"Full-datset-languages-check-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Full datset languages check</a></span></li></ul></li><li><span><a href=\"#Write-out-data\" data-toc-modified-id=\"Write-out-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Write out data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small subset initial import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import preprocessor as tweet_preprocessor\n",
    "pd.set_option('max_colwidth', None)\n",
    "path = 'output_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 1000 data/tweets.json > data/t.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.4 ms, sys: 0 ns, total: 28.4 ms\n",
      "Wall time: 29.1 ms\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   contributors               0 non-null      float64       \n",
      " 1   coordinates                0 non-null      float64       \n",
      " 2   created_at                 1000 non-null   datetime64[ns]\n",
      " 3   display_text_range         1000 non-null   object        \n",
      " 4   entities                   1000 non-null   object        \n",
      " 5   favorite_count             1000 non-null   int64         \n",
      " 6   favorited                  1000 non-null   bool          \n",
      " 7   geo                        0 non-null      float64       \n",
      " 8   id                         1000 non-null   int64         \n",
      " 9   id_str                     1000 non-null   int64         \n",
      " 10  in_reply_to_screen_name    44 non-null     object        \n",
      " 11  in_reply_to_status_id      37 non-null     float64       \n",
      " 12  in_reply_to_status_id_str  37 non-null     float64       \n",
      " 13  in_reply_to_user_id        44 non-null     float64       \n",
      " 14  in_reply_to_user_id_str    44 non-null     float64       \n",
      " 15  is_quote_status            1000 non-null   bool          \n",
      " 16  lang                       1000 non-null   object        \n",
      " 17  place                      0 non-null      float64       \n",
      " 18  retweet_count              1000 non-null   int64         \n",
      " 19  retweeted                  1000 non-null   bool          \n",
      " 20  screen_name                1000 non-null   object        \n",
      " 21  source                     1000 non-null   object        \n",
      " 22  text                       1000 non-null   object        \n",
      " 23  truncated                  1000 non-null   bool          \n",
      " 24  user_id                    1000 non-null   int64         \n",
      "dtypes: bool(4), datetime64[ns](1), float64(8), int64(5), object(7)\n",
      "memory usage: 168.1+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_path = 'data/t.json'\n",
    "\n",
    "%time df = pd.read_json(tweets_path, lines=True)\n",
    "df.info()\n",
    "columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = ['contributors', 'coordinates', 'geo', 'place']\n",
    "columns = [x for x in columns if x not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorited</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorited is_quote_status retweeted truncated\n",
       "count       1000            1000      1000      1000\n",
       "unique         1               1         1         1\n",
       "top        False           False     False     False\n",
       "freq        1000            1000      1000      1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].describe(include = bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to get data from the 'entities' dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_entities(row, type_field, value_field):\n",
    "    field_values = []\n",
    "    x = row['entities'][type_field]\n",
    "    for i in range(len(x)):\n",
    "        field_values.append(x[i][value_field])\n",
    "    return field_values\n",
    "\n",
    "def get_hashtags(row):\n",
    "    values = get_from_entities(row,\n",
    "                               type_field='hashtags',\n",
    "                               value_field='text')\n",
    "    hashtags.update(values)\n",
    "    for h in values:\n",
    "        tweets_hashtags.append([row['id'],h])\n",
    "    return values\n",
    "\n",
    "def get_mentions(row):\n",
    "    values = get_from_entities(row,\n",
    "                               type_field='user_mentions',\n",
    "                               value_field='screen_name')\n",
    "    mentions.update(values)\n",
    "    for h in values:\n",
    "        tweets_mentions.append([row['id'],h])\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtags'] = df.apply(get_from_entities, axis=1,\n",
    "                          type_field='hashtags',\n",
    "                          value_field='text')\n",
    "df['mentions'] = df.apply(get_from_entities, axis=1,\n",
    "                           type_field='user_mentions',\n",
    "                           value_field='screen_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The twitter client might be useful in another context but not here\n",
    "# I have no need for display_text_range when the text is available\n",
    "# Remove 'entities' now that I have hashtags and mentions\n",
    "unwanted = ['favorited', 'is_quote_status','retweeted','truncated',\n",
    "            'entities', 'source', 'display_text_range']\n",
    "columns = [x for x in columns if x not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.142000</td>\n",
       "      <td>1.231684e+09</td>\n",
       "      <td>1.231684e+09</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.705780e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.556908</td>\n",
       "      <td>1.139083e+08</td>\n",
       "      <td>1.139083e+08</td>\n",
       "      <td>0.044699</td>\n",
       "      <td>4.346137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.774186e+08</td>\n",
       "      <td>8.774186e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.558312e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.170882e+09</td>\n",
       "      <td>1.170882e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.595500e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.247574e+09</td>\n",
       "      <td>1.247574e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.816678e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.318437e+09</td>\n",
       "      <td>1.318437e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.941846e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.402545e+09</td>\n",
       "      <td>1.402545e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.677811e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       favorite_count            id        id_str  retweet_count       user_id\n",
       "count     1000.000000  1.000000e+03  1.000000e+03    1000.000000  1.000000e+03\n",
       "mean         0.142000  1.231684e+09  1.231684e+09       0.002000  1.705780e+07\n",
       "std          0.556908  1.139083e+08  1.139083e+08       0.044699  4.346137e+06\n",
       "min          0.000000  8.774186e+08  8.774186e+08       0.000000  5.558312e+06\n",
       "25%          0.000000  1.170882e+09  1.170882e+09       0.000000  1.595500e+07\n",
       "50%          0.000000  1.247574e+09  1.247574e+09       0.000000  1.816678e+07\n",
       "75%          0.000000  1.318437e+09  1.318437e+09       0.000000  1.941846e+07\n",
       "max          8.000000  1.402545e+09  1.402545e+09       1.000000  2.677811e+07"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].describe(include=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few tweets are 'liked' so lose 'favorite_count'\n",
    "unwanted = ['id_str', 'favorite_count']\n",
    "columns = [x for x in columns if x not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Citizensnews</td>\n",
       "      <td>en</td>\n",
       "      <td>henrymcmaster</td>\n",
       "      <td>Attending a Whip Team meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>986</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       in_reply_to_screen_name  lang    screen_name  \\\n",
       "count                       44  1000           1000   \n",
       "unique                      40     7             31   \n",
       "top               Citizensnews    en  henrymcmaster   \n",
       "freq                         2   986            117   \n",
       "\n",
       "                                 text  \n",
       "count                            1000  \n",
       "unique                            994  \n",
       "top     Attending a Whip Team meeting  \n",
       "freq                                2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].describe(include=np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both screen_name and user_id are unique to the tweeter.\n",
    "I'll lose user_id and match/join on screen_name if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = ['user_id']\n",
    "columns = [x for x in columns if x not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   created_at                 1000 non-null   datetime64[ns]\n",
      " 1   id                         1000 non-null   int64         \n",
      " 2   in_reply_to_screen_name    44 non-null     object        \n",
      " 3   in_reply_to_status_id      37 non-null     float64       \n",
      " 4   in_reply_to_status_id_str  37 non-null     float64       \n",
      " 5   in_reply_to_user_id        44 non-null     float64       \n",
      " 6   in_reply_to_user_id_str    44 non-null     float64       \n",
      " 7   lang                       1000 non-null   object        \n",
      " 8   retweet_count              1000 non-null   int64         \n",
      " 9   screen_name                1000 non-null   object        \n",
      " 10  text                       1000 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(4)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df[columns].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replies are < 4% of the data so ignore `in_reply_to_*`.\n",
    "Also lose the `lang` column but it will be used briefly before the cleaned\n",
    "*full* data set is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = ['in_reply_to_status_id_str',\n",
    "            'in_reply_to_status_id',\n",
    "            'in_reply_to_user_id_str',\n",
    "            'in_reply_to_user_id',\n",
    "            'in_reply_to_screen_name',\n",
    "            'lang']\n",
    "columns = [x for x in columns if x not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contributors', 'coordinates', 'created_at', 'display_text_range',\n",
       "       'entities', 'favorite_count', 'favorited', 'geo', 'id', 'id_str',\n",
       "       'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
       "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
       "       'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'place',\n",
       "       'retweet_count', 'retweeted', 'screen_name', 'source', 'text',\n",
       "       'truncated', 'user_id', 'hashtags', 'mentions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full datset languages check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be able to store just what's required from the full tweets data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_path = 'data/tweets.json'\n",
    "chunksize = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a full list of languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 1226949, 'nl': 88, 'es': 5108, 'fr': 674, 'und': 8137, 'sv': 57, 'ro': 261, 'is': 17, 'tl': 245, 'ht': 107, 'in': 346, 'de': 223, 'et': 205, 'pl': 183, 'no': 65, 'da': 121, 'fi': 88, 'sl': 23, 'it': 120, 'cy': 74, 'cs': 15, 'eu': 19, 'lv': 13, 'pt': 142, 'vi': 11, 'th': 1, 'hi': 13, 'hu': 9, 'tr': 16, 'lt': 23, 'zh': 1, 'uk': 5, 'ko': 1, 'ja': 3, 'iw': 3, 'ru': 2, 'fa': 2}\n",
      "CPU times: user 56.6 s, sys: 629 ms, total: 57.3 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def count_languages(chunk, languages):\n",
    "    for lang in chunk['lang']:\n",
    "        if lang not in languages:\n",
    "            languages[lang] = 0\n",
    "        languages[lang] += 1\n",
    "        \n",
    "# This takes a while but at least it's comprehensive\n",
    "# Remember Twitter *autodetects* the tweet's language\n",
    "# so chances are most 'und' is from English speakers.\n",
    "languages = dict()\n",
    "for chunk in pd.read_json(tweets_path, lines=True, chunksize=chunksize):\n",
    "    count_languages(chunk, languages)\n",
    "print (languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 98.7% of the tweets are in English so I'll lose tweets where\n",
    "`lang != 'en'` as well as the `lang` column itself.\n",
    "\n",
    "Add the hashtags and mentions columns too, before writing to csv.\n",
    "Sadly parquet et al. do not support appending data.\n",
    "(HDF does but I don't have time to learn enough about it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a list of tweeters' screen names, mentions and hashtags\n",
    "# These will all need to have tables (see ERD)\n",
    "hashtags = set() # Global\n",
    "mentions = set() # Global\n",
    "tweets_hashtags = [] # Global\n",
    "tweets_mentions = [] # Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output columns: ['created_at', 'id', 'retweet_count', 'screen_name', 'text']\n",
      "CPU times: user 3min 39s, sys: 731 ms, total: 3min 39s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This builds up data needed for the hashtag, mention, tweet_hashtag and\n",
    "# tweet_mention relations as well as the main tweets table.\n",
    "# It takes a while to run!\n",
    "outpath = path+'tweet.csv'\n",
    "\n",
    "#Create \"tweets\" table headers\n",
    "df[df['id']==None][columns].to_csv(outpath,\n",
    "                                   mode='w',\n",
    "                                   header=True,\n",
    "                                   index=False,\n",
    "                                   line_terminator='r')\n",
    "\n",
    "for chunk in pd.read_json(tweets_path, lines=True, chunksize=chunksize):\n",
    "    # Lose non-English tweets\n",
    "    chunk = chunk[chunk['lang'] == 'en']\n",
    "    \n",
    "    # Add hashtags and mentions from each tweet\n",
    "    # These functions access global variables to create\n",
    "    # the four tables mentioned above.\n",
    "    chunk['hashtags'] = chunk.apply(get_hashtags, axis=1)\n",
    "    chunk['mentions'] = chunk.apply(get_mentions, axis=1)\n",
    "    chunk['text'] = chunk['text'].apply(tweet_preprocessor.clean)\n",
    "    \n",
    "    # I'm not going to refactor the chunk processing but I will\n",
    "    # no longer need the 'hashtags' nor 'mentions' columns\n",
    "    unwanted = ['hashtags', 'mentions']\n",
    "    columns = [x for x in columns if x not in unwanted]\n",
    "    \n",
    "    # Select columns\n",
    "    chunk = chunk[columns]\n",
    "\n",
    "    # Write to CSV\n",
    "    chunk.to_csv(outpath,\n",
    "                 mode='a',\n",
    "                 header=False,\n",
    "                 index=False,\n",
    "                 line_terminator='r')\n",
    "\n",
    "print(f'Output columns: {columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'retweet_count', 'screen_name', 'text'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these columns should match the ERD (for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the secondary tables\n",
    "hashtags = pd.DataFrame(hashtags, columns=['hashtag'], dtype=str)\n",
    "mentions = pd.DataFrame(mentions, columns=['mention'], dtype=str)\n",
    "tweets_hashtags = pd.DataFrame(tweets_hashtags,columns=['tweet_id','hashtag'])\n",
    "tweets_mentions = pd.DataFrame(tweets_mentions,columns=['tweet_id','mention'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of secondary tables\n",
      "-------------------------\n",
      "hashtag: (96973, 1)\n",
      "mention: (132149, 1)\n",
      "tweet_hashtag: (893921, 2)\n",
      "tweet_mention: (998478, 2)\n"
     ]
    }
   ],
   "source": [
    "# Summarise scondary table sizes\n",
    "print('Sizes of secondary tables')\n",
    "print('-------------------------')\n",
    "print(f'hashtag: {hashtags.shape}')\n",
    "print(f'mention: {mentions.shape}')\n",
    "print(f'tweet_hashtag: {tweets_hashtags.shape}')\n",
    "print(f'tweet_mention: {tweets_mentions.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output secondary tables\n",
    "hashtags.to_csv(path+'hashtag.csv', index=False)\n",
    "mentions.to_csv(path+'mention.csv', index=False)\n",
    "tweets_hashtags.to_csv(path+'tweet_hashtag.csv', index=False)\n",
    "tweets_mentions.to_csv(path+'tweet_mention.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
